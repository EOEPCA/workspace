{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>The documentation for the <code>Workspace</code> building block is organised as follows\u2026</p> <ul> <li>Introduction   Introduction to the BB - including summary of purpose and capabilities.</li> <li>Getting Started   Quick start instructions - including installation, e.g. of a local instance.</li> <li>Design   Description of the BB design - including its subcomponent architecture and interfaces.</li> <li>Usage   Tutorials, How-tos, etc. to communicate usage of the BB.</li> <li>Administration   Configuration and maintenance of the BB.</li> <li>API   Details of APIs provided by the BB - including endpoints, usage descriptions and examples etc.</li> </ul>"},{"location":"#about-workspace","title":"About <code>Workspace</code>","text":"<p>The <code>Workspace</code> building block provides a comprehensive solution for storing assets and offering services like cataloguing, data (cube) access, and visualization to explore stored assets. Workspaces can cater to individual users or serve as collaborative spaces for groups or projects.</p>"},{"location":"#workspace-controller","title":"Workspace Controller","text":"<p>The Workspace Controller acts as an API for workspace administration. This includes:</p> <ul> <li>Provisioning and Lifecycle Management: Creating, updating, and deleting workspaces.</li> <li>Workspace Instance Management: Configuring and managing individual workspace instances and their associated services [BR066].</li> <li>REST API: Providing a REST API for workspace administration [BR067].</li> <li>GitOps Approach: Enabling workspace owners to manage their workspace offerings through a declarative GitOps approach [BR070].</li> <li>Extensibility: Allowing for the extension of managed services by reusing existing building blocks [BR068, BR069].</li> <li>Resource Efficiency: Designing for efficient use of platform resources [BR072].</li> <li>Service Management: Enabling users to manage (enable, disable, suspend) the services provisioned within their workspace [BR071].</li> </ul>"},{"location":"#storage-controller","title":"Storage Controller","text":"<p>The Storage Controller provides an API for self-service management of storage buckets. Users can:</p> <ul> <li>Create and Manage Buckets: Create and manage object storage buckets via an API associated with the workspace [BR073, BR074].</li> <li>Bucket Management: Manage buckets, including listing details like bucket name, service URL, and S3 access credentials [BR075].</li> <li>HTTP Access: Access buckets via direct HTTP access, supporting HTTP range requests and allowing users to upload assets [BR076, BR077].</li> <li>IAM Integration: Secure S3 and HTTP access by integrating with the IAM building block [BR078].</li> <li>External Storage Support: Register and integrate external S3-compatible object storage services [BR079].</li> <li>Unique Identification: Uniquely identify each S3 object storage service [BR080].</li> </ul>"},{"location":"#workspace-services","title":"Workspace Services","text":"<p>The Workspace Services comprise an extensible set of services that can be provisioned within the workspace. These services include:</p> <ul> <li>Resource Registration/Discovery: Enabling the registration and discovery of resources.</li> <li>Data &amp; Datacube Access: Providing access to data and data cubes.</li> <li>Extensibility: Supporting arbitrary applications and tooling by reusing existing Helm charts for databases (e.g., PostGIS), JupyterHub, ML tooling (e.g., MLFlow, Tensorboard) [BR081, BR084].</li> <li>Public APIs: Exposing all workspace services via their public APIs.</li> <li>Scoped Access: Providing access to resources scoped according to the owning projects and users [BR082, BR083].</li> </ul>"},{"location":"#workspace-user-interface","title":"Workspace User Interface","text":"<p>The Workspace User Interface provides a web-based interface for:</p> <ul> <li>Workspace Lifecycle Management: Creating, listing, updating, and deleting workspaces.</li> <li>Workspace Resource Management: Managing workspace resources, including services, storage buckets, registered resources, and DOI registrations [BR085].</li> </ul>"},{"location":"admin/configuration/","title":"Configuration","text":"<p>How the BB is configured - with examples etc.</p>"},{"location":"admin/maintenance/","title":"Maintenance","text":"<p>Administrative and remedial activities to be performed on a running BB instance</p>"},{"location":"api/endpoint-specification/","title":"Specification","text":"<p>Details of the API specification.</p>"},{"location":"api/usage/","title":"Usage","text":"<p>API usage descriptions and examples.</p>"},{"location":"api/workspace/","title":"API Reference","text":"<p>Packages:</p> <ul> <li>epca.eo/v1beta1</li> </ul>"},{"location":"api/workspace/#epcaeov1beta1","title":"epca.eo/v1beta1","text":"<p>Resource Types:</p> <ul> <li>XWorkspace</li> </ul>"},{"location":"api/workspace/#xworkspace","title":"XWorkspace","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required apiVersion string epca.eo/v1beta1 true kind string XWorkspace true metadata object Refer to the Kubernetes API documentation for the fields of the `metadata` field. true spec object true status object false"},{"location":"api/workspace/#xworkspacespec","title":"XWorkspace.spec","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required owner string true defaultBucket string false extraBuckets []string Default: [] false grants []object Default: [] false linkedBuckets []string Default: [] false members []string Default: [] false subscription enum Enum: gold, silver, bronze, trial Default: trial false vcluster enum Enum: active, suspended, disabled Default: active false"},{"location":"api/workspace/#xworkspacespecgrantsindex","title":"XWorkspace.spec.grants[index]","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required bucket string true grantees []string true"},{"location":"api/workspace/#xworkspacestatus","title":"XWorkspace.status","text":"<p><sup><sup>\u21a9 Parent</sup></sup></p> Name Type Description Required"},{"location":"design/iam-concept/","title":"Workspace Access and IAM Integration concept","text":""},{"location":"design/iam-concept/#workspace-specification","title":"Workspace Specification","text":"<p>The workspace specification defines key attributes of a workspace, including its unique name (e.g. <code>ws-example-78</code>) and the username of its owner. These attributes play a crucial role in Identity and Access Management (IAM) within the EOEPCA system.</p>"},{"location":"design/iam-concept/#iam-entities-provisioned-per-workspace","title":"IAM Entities Provisioned per Workspace","text":"<p>When a workspace is created, the provisioning pipeline automatically establishes the following IAM entities in Keycloak:</p> <ul> <li>Keycloak Client: A non-confidential OAuth2 client is created, named after the workspace (e.g. <code>ws-example-78</code>). This client supports:</li> <li>OAuth2 Standard Flow</li> <li>Implicit Flow</li> <li>Device Flow</li> <li> <p>A client role called <code>ws_access</code></p> </li> <li> <p>Keycloak Group: A group with the same name as the workspace (e.g. <code>ws-example-78</code>) is created. This group includes a role mapping to the <code>ws_access</code> role of the client.</p> </li> </ul> <p>This setup ensures that any user added to the workspace-specific group will have access to that workspace. Since users can belong to multiple groups (e.g. <code>ws-example-78</code> and <code>ws-example-79</code>), they will automatically gain access to all corresponding workspaces if added to these groups.</p> <ul> <li>Keycloak Membership for the Owner: The workspace owner is automatically assigned membership in the workspace group, ensuring they have access to their own workspace.</li> </ul>"},{"location":"design/iam-concept/#future-development","title":"Future Development","text":"<p>EOEPCA plans to introduce tooling that allows workspace owners to manage access for other users (see #35). Currently, operators can manually add users to workspace groups via Keycloak\u2019s tooling or leverage GitOps reconciliation mechanisms between Kubernetes and Keycloak.</p>"},{"location":"design/iam-concept/#what-does-workspace-access-mean","title":"What Does Workspace Access Mean?","text":"<p>Workspace provisioning establishes key resources, including:</p> <ul> <li>Storage Resources: Dedicated object storage buckets</li> <li>Preconfigured Deployments: Services such as the Workspace UI, bundled with a storage layer for data management</li> </ul> <p>To facilitate access, the following mechanisms are in place:</p>"},{"location":"design/iam-concept/#object-storage-access","title":"Object Storage Access","text":"<p>A dedicated API endpoint allows users or authorized services to request credentials for workspace object storage. The endpoint follows this format:</p> <pre><code>https://workspace-api.apx.develop.eoepca.org/workspaces/&lt;workspace-name&gt;\n</code></pre> <p>For example:</p> <pre><code>https://workspace-api.apx.develop.eoepca.org/workspaces/ws-example-78\n</code></pre>"},{"location":"design/iam-concept/#workspace-ui-storage-layer-access","title":"Workspace UI &amp; Storage Layer Access","text":"<p>Each workspace is assigned a dedicated subdomain with a valid TLS certificate:</p> <pre><code>https://&lt;workspace-name&gt;.apx.develop.eoepca.org/\n</code></pre> <p>For example:</p> <pre><code>https://ws-example-79.apx.develop.eoepca.org/\n</code></pre> <p>Access to these resources is restricted based on IAM policies: users must have the <code>ws_access</code> role for the corresponding client in order to gain entry.</p>"},{"location":"design/iam-concept/#authorization-via-opa-policies","title":"Authorization via OPA Policies","text":"<p>EOEPCA has adopted Open Policy Agent (OPA) to manage authorization. This allows for:</p> <ul> <li>GitOps-style declarative specification of access policies, for above workspace components see here</li> <li>Seamless integration with APISix Ingress via the OPA plugin, working in conjunction with the OpenID Connect plugin</li> </ul> <p>While Keycloak\u2019s native authorization capabilities were considered, OPA was chosen due to its flexibility and compatibility with EOEPCA\u2019s infrastructure. For further details on the IAM architecture and decision-making process, refer to the IAM BB Documentation</p>"},{"location":"design/motivation/","title":"Motivation for the changes between workspace v1 and v2","text":"<p>The initial v1 version of the workspace had several design flaws, making it inflexible and difficult for platform operators to use:</p> <ul> <li>Each workspace had a fixed number of components, including exactly one bucket and a predefined list of services that were available to all users. This rigid structure made it difficult to customize workspaces for specific needs.</li> <li>The services were deployed into Kubernetes through an explicit call on the workspace-api, using a provisioning pipeline defined in code. Upgrading these services to newer versions for all users was difficult, as it required additional workspace-api calls for redeployment. Extending the list of services for specific users was even more challenging.</li> <li>Provisioning of infrastructure components like the object storage bucket(s) and associated IAM policies and user are always operator specific and the customization possibilities with custom webhooks were cumbersome.</li> <li>Kubernetes namespaces were used for multi-tenancy, making some operations manual (e.g. installing CRDs) or impossible for an operator (using different versions of a CRD, RBAC with cluster wide permissions,\u2026).</li> </ul> <p>The v2 version of the workspace mitigates these issues:</p> <ul> <li>The workspace controller automatically creates a dedicated space in a Git repository (either a new repository or a separate folder) for each workspace, allowing for declarative descriptions of all deployed services with their current software version and configuration, so this information can be easily inspected. Custom services can be installed via GitOps mechanisms and are declaratively stated the same way. </li> <li>The provisioning pipeline is declaratively stated and can be adapted by the operator. Best-practise blueprints are shared in the workspace EOEPCA repository. The provisioning pipeline is continuously reconciled, always trying to match the desired state with the observed state. Updates of services can therefore be selectively or globally triggered via Git.</li> <li>The vcluster tooling is automatically deployed per namespace, providing a dedicated Kubernetes API server runtime for each workspace.</li> </ul>"},{"location":"design/overview/","title":"Architecture","text":""},{"location":"design/overview/#overview","title":"Overview","text":"<p>As laid out in the System Architecture document the Workspace building-block comprises:</p> <ul> <li> <p>Workspace Controller   Platform-level API for administration of workspaces with capabilities of the Workspace Controller API for Workspace Provisioning and Workspace Utilisation</p> </li> <li> <p>Storage Controller &amp; Storage Layer   User-level API for management of storage buckets with capabilities of the Storage Controller API for Bucket Provisioning, Bucket Management and Bucket Federation and of the Storage Layer API and UI for Bucket Content Browsing and specific Bucket Content Sharing via HTTP.</p> </li> <li> <p>Workspace Services   Comprising the extensible set of Services dynamically instantiated on a workspace within the scope of a project/user.</p> </li> <li> <p>Workspace &amp; Storage UI Web-enabled user interfaces designed for operators resp. users, offering relevant capabilities in an intuitive manner.</p> </li> </ul>"},{"location":"design/overview/#design","title":"Design","text":"<p>A workspace involves allocating compute and storage resources tailored to a specific project or user. By leveraging Kubernetes and the multi-tenant features of the vCluster project, a balance between isolation and cost efficiency is achieved while retaining the benefits of Kubernetes. As a result, a workspace is implemented as a vCluster installation, hosting multiple \u201cvirtual\u201d Kubernetes clusters within a single \u201chost\u201d Kubernetes cluster.</p> <p>In line with Kubernetes native concepts, a workspace is defined using a new Kubernetes Workspace CRD (Custom Resource Definition), with a corresponding Kubernetes Workspace Controller responsible for reconciling the desired state as specified in the Workspace CRD manifest on the cluster.</p> <p>The reconciliation process within the Workspace Controller for each workspace manifest involves the following steps</p> <ul> <li>Establish a dedicated namespace for each project/user in the Host Kubernetes cluster.</li> <li>Apply Kubernetes policies such as ResourceQuota, LimitRange, and NetworkPolicy to the namespace.</li> <li>Deploy a vCluster with best-practice configurations within the namespace.</li> <li>Create a new Git repository (or a folder in an existing Git repository, depending on the global setup) to store the desired manifests for Workspace Services to be reconciled through Flux GitOps principles.</li> <li>Connect Flux to reconcile the Git repository (or folder) with the vCluster.</li> <li>Implement Kubernetes Validating Webhooks to enforce bucket creation policies, such as maximum number and size, and naming pattern conventions, within the namespace.</li> </ul> <p>and finally exposes</p> <ul> <li>vCluster credentials for direct \u201cvirtual\u201d Kubernetes cluster access,</li> <li>Git settings used for Flux,</li> <li>The current reconciliation state.</li> </ul> <p>An operator can establish a workspace for a project/user imperatively via the Kubernetes API by submitting a Workspace manifest or by following a declarative GitOps approach with the Workspace manifest checked in to Git. The Kubernetes Web UI Dashboard may be deployed on the \u201chost\u201d Kubernetes cluster supporting the operator process in a graphical way during Workspace Provisioning. For Workspace Utilization dedicated Grafana dashboard are established tracking workspace metrics.</p> <p>Note: The EOEPCA 1.x workspace API is obsolete and not included in EOEPCA+.</p> <p>A workspace can be accessed via the Kubernetes API and is integrated with GitOps tooling through Flux. Both common and optional components can be installed for a specific project or user. By default, the template GitRepository includes the Storage Controller API, responsible for Bucket Provisioning, Bucket Management and Bucket Federation, the Storage Layer API and UI for Bucket Content Browsing and specific Bucket Content Sharing via HTTP, as well as common EOEPCA Building Blocks (BB) for resource discovery and EO data management. These Workspace Services can be enriched with additional tools from the EOEPCA Application Hub BB and EOEPCA MLHub BB.</p> <p>The Storage Controller is tasked with reconciling the desired state as specified in the storage manifest (for the new Kubernetes Storage CRD). It uses Terraform internally for the reconciliation process, with documentation providing specifications for common cloud providers like AWS as examples.</p> <p>Note: Kubernetes Validating Webhooks established in the namespace of the \u201chost\u201d cluster will enforce proper bucket creation policies.</p> <p>The reconciliation process within the Storage Controller for each storage manifest includes the following steps:</p> <ul> <li>Establish a dedicated bucket or connect a federated bucket.</li> <li>Configure bucket access and CORS policies for the bucket.</li> </ul> <p>and finally exposes:</p> <ul> <li>Bucket credentials,</li> <li>Access URL,</li> <li>The current reconciliation state.</li> </ul> <p>The Storage Layer is implemented as a microservice that allows users to search and browse through the content of the storage buckets connected to a given workspace using directory-based file system semantics. For \u201ctext files\u201d like markdown, direct preview capabilities are provided. Besides navigation and search, the main use case for the Storage Layer is sharing specific content via pre-signed URLs, enabling direct HTTP access without requiring user authentication.</p> <p>Note: The EOEPCA+ team acknowledges that object storage solutions like AWS S3 store content as key-value pairs without true directory functionality, which can have performance implications when using a file system abstraction. By supporting only read-only browsing and not allowing modifications like move or rename operations, treating bucket content as files within the storage layer has been identified as the most intuitive approach for users to navigate content hierarchies.</p>"},{"location":"design/vcluster/","title":"Understanding vCluster: Setup and Operational Considerations","text":"<p><code>vCluster</code> offers significantly more flexibility and stronger multi-tenancy guarantees than exposing a single Kubernetes namespace. However, for long-term sustainable operation, there are still several architectural and operational decisions that must be made by the platform operator. This document outlines our current setup and highlights these decisions, particularly with regard to static and dynamic operation modes.</p>"},{"location":"design/vcluster/#different-operational-models-for-vcluster","title":"Different Operational Models for vCluster","text":"<p>In the static mode, vClusters are provisioned ahead of time and persist over their lifetime. Optionally, they can be scaled down to zero. Note that this only works if an <code>ownerReference</code> is configured to ensure that dependent user workloads (such as pods) are also shut down correctly. This mode is resource-stable but incurs a constant footprint.</p> <p>In contrast, the dynamic mode allows vClusters to be spawned on-demand based on user requests. This makes the ephemeral nature of the environment clearer to users, while their storage is persistently mounted into pods. In this setup, a proper UI indicating whether a vCluster is currently running or not is even more necessary, highlighting that user state may be ephemeral or must be externalized. This can be supported by tooling, but it also requires proper status indication and user guidance.</p> <p>In a static vCluster deployment, each instance has a fixed compute and storage footprint. We use the <code>k0s</code> Kubernetes distribution, which results in a number of always-on components: the control plane container, the init container for bootstrapping <code>k0s</code>, the vCluster proxy, and a metrics server.</p> <p>This introduces a baseline resource overhead. Even when idle, a vCluster typically consumes around 300\u2013500MiB of memory and 0.1\u20130.2 vCPU. These values should be monitored over time and optimized based on workload patterns.</p> <p>Each vCluster instance also requires a dedicated PersistentVolumeClaim (PVC) for storing control plane metadata such as Kubernetes Custom Resources. This volume is provisioned using a specific <code>storageClassName</code>.</p> <p>In addition, PVCs for user code and data are mounted into pods. These must support <code>ReadWriteMany</code> access modes \u2014 typically via NFS \u2014 since multiple containers may need access to the same volume. However, NFS can become a performance bottleneck when working with large numbers of small files, so this should be evaluated based on usage patterns.</p>"},{"location":"design/vcluster/#resource-synchronization","title":"Resource Synchronization","text":"<p>To enable access to shared infrastructure while maintaining strong workspace isolation, we synchronize key Kubernetes resources between the virtual cluster and the host cluster.</p> <p>PVCs created inside the vCluster are automatically backed by volumes on the host. Host-side storage classes are made visible to the vCluster, allowing user pods to dynamically provision volumes.</p> <p>Secrets are selectively mapped into the virtual cluster using a controlled mapping strategy. All secrets from the host namespace where the vCluster runs are automatically mounted into the <code>default</code> namespace inside the vCluster. This enables secure injection of credentials (such as kubeconfigs or S3 tokens) without overexposing host resources.</p> <p>ServiceAccounts created inside the vCluster are also synced back to the host cluster. This supports identity mapping and integration with host-level RBAC and access policies.</p>"},{"location":"design/vcluster/#networking-and-ingress-design","title":"Networking and Ingress Design","text":"<p>We deliberately do not enable ingress inside the vCluster. Instead, all routing is handled by a centralized ingress controller operating in the host cluster (e.g., APISIX or Traefik). This model aligns with patterns used in multi-tenant platforms like JupyterHub, where a single internal component acts as a gateway to all services in a workspace.</p> <p>This approach simplifies routing, centralizes TLS termination, and allows authentication and access policy enforcement to be handled in a uniform way by the platform operator.</p>"},{"location":"design/vcluster/#tls-and-san-handling","title":"TLS and SAN Handling","text":"<p>We expose the vCluster control plane via a unique server URL and context, with custom SANs configured using the <code>proxy.extraSANs</code> config option. This allows users to interact with their vCluster instance using standard tools like <code>kubectl</code>, while still benefiting from certificate-based validation.</p> <p>To support this, TLS passthrough must be enabled at the outer ingress or load balancer. TLS must be terminated inside the vCluster to allow the custom SAN to be validated correctly.</p>"},{"location":"design/vcluster/#coredns-integration","title":"CoreDNS Integration","text":"<p>Each vCluster runs its own CoreDNS instance. This ensures that Kubernetes-internal DNS resolution works independently for tenant workloads.</p> <p>Where needed, the vCluster CoreDNS can forward queries to the host DNS for resolving external services such as persistent volume provisioning endpoints, container registries, or federated identity services. This design ensures seamless interoperation with the host cluster while preserving namespace isolation within the vCluster.</p>"},{"location":"getting-started/more-getting-started/","title":"More getting started\u2026","text":"<p>Further elaboration of Getting Started\u2026</p>"},{"location":"getting-started/quick-start/","title":"Quick Start","text":"<p>Quick start instructions - including installation, e.g. of a local instance.</p>"},{"location":"usage/howtos/","title":"How-Tos","text":"<p>How-tos to communicate usage by example.</p>"},{"location":"usage/howtos/#workspace-building-block","title":"Workspace Building Block","text":""},{"location":"usage/howtos/#uc1-dedicated-workspace-for-users-and-projects","title":"UC1: Dedicated Workspace for Users and Projects","text":"<p>User Story: As a user, I want to use an instance of a building block or component (e.g., resource discovery, data access) which is dedicated to my own or my project workspace.</p> <p>Tech Standards: Kubernetes, GitOps</p> <p>Epic: E5310</p> <p>Building Block: Workspace</p> <p>How-To:</p> <ol> <li>Create a Workspace: Use the Workspace Controller to create a new workspace dedicated to your project or individual use.</li> <li>Provision Services:  Utilize the Workspace Controller to provision the necessary services within your workspace, such as resource discovery, data access, or visualization tools.</li> <li>Access Services: Access the provisioned services within your workspace using the provided APIs or user interfaces.</li> </ol>"},{"location":"usage/howtos/#uc2-workspace-provisioning-and-management","title":"UC2: Workspace Provisioning and Management","text":"<p>User Story: As a platform operator, I want to leverage a SOTA solution to provision and manage workspaces for projects/groups.</p> <p>Tech Standards: Kubernetes, GitOps</p> <p>Epic: E5310</p> <p>Building Block: Workspace</p> <p>How-To:</p> <ol> <li>Configure Workspace Templates: Define templates for different workspace types (e.g., individual user, project team) using GitOps principles.</li> <li>Provision Workspaces: Use the Workspace Controller to provision new workspaces based on the defined templates.</li> <li>Manage Workspaces: Monitor and manage workspace resources, including services, storage, and user access, through the Workspace Controller.</li> </ol>"},{"location":"usage/howtos/#storage-building-block","title":"Storage Building Block","text":""},{"location":"usage/howtos/#uc3-s3-object-storage-for-data-organization","title":"UC3: S3 Object Storage for Data Organization","text":"<p>User Story: As a user, I want an S3 object storage to organize and curate data.</p> <p>Tech Standards: S3</p> <p>Epic: E5350</p> <p>Building Block: Workspace</p> <p>How-To:</p> <ol> <li>Create Storage Buckets: Use the Storage Controller to create new S3 buckets within your workspace.</li> <li>Upload Data: Upload your data files to the created buckets using the provided S3 API or HTTP access.</li> <li>Organize Data: Organize your data within the buckets using folders and file naming conventions.</li> </ol>"},{"location":"usage/howtos/#security-building-block","title":"Security Building Block","text":""},{"location":"usage/howtos/#uc4-iam-control-for-users","title":"UC4: IAM Control for Users","text":"<p>User Story: As a platform operator, I want to keep control on IAM for my users.</p> <p>Tech Standards: OAuth2</p> <p>Epic: E5340</p> <p>Building Block: Workspace</p> <p>How-To:</p> <ol> <li>Configure IAM Roles: Define IAM roles with specific permissions for different user groups (e.g., data scientists, project managers).</li> <li>Assign Roles to Users: Assign the appropriate IAM roles to users based on their responsibilities and access needs.</li> <li>Monitor Access: Monitor user access and activity logs to ensure security and compliance.</li> </ol>"},{"location":"usage/howtos/#application-hub-building-block","title":"Application Hub Building Block","text":""},{"location":"usage/howtos/#uc5-delegated-workspace-service-instantiation","title":"UC5: Delegated Workspace Service Instantiation","text":"<p>User Story: As a platform operator, I want to delegate Workspace Service instantiation to the end-users without compromising security.</p> <p>Tech Standards: Kubernetes, Helm</p> <p>Epic: E5320</p> <p>Building Block: Workspace, Application Hub, MLOps</p> <p>How-To:</p> <ol> <li>Create Helm Charts: Package Workspace Services as Helm charts, including dependencies and configuration options.</li> <li>Publish Charts to Application Hub: Publish the Helm charts to the Application Hub, making them accessible to users.</li> <li>User Service Instantiation: Allow users to install and configure Workspace Services from the Application Hub using Helm.</li> </ol>"},{"location":"usage/howtos/#resource-management-building-block","title":"Resource Management Building Block","text":""},{"location":"usage/howtos/#uc6-runtime-resource-management","title":"UC6: Runtime Resource Management","text":"<p>User Story: As a platform operator, I want to easily turn on and off projects/groups runtime resources to save costs.</p> <p>Tech Standards: Kubernetes</p> <p>Epic: E5320</p> <p>Building Block: Workspace</p> <p>How-To:</p> <ol> <li>Configure Resource Scaling: Define resource scaling policies for different workspace types or services.</li> <li>Automate Resource Management: Use Kubernetes features like autoscaling and resource quotas to automatically manage resource allocation based on usage patterns.</li> <li>Monitor Resource Usage: Monitor resource consumption and adjust scaling policies as needed to optimize costs.</li> </ol>"},{"location":"usage/howtos/#data-management-building-block","title":"Data Management Building Block","text":""},{"location":"usage/howtos/#uc7-data-integration-and-collaboration","title":"UC7: Data Integration and Collaboration","text":"<p>User Story: As a user, I want to integrate (copy as well as referencing) data in the project/group space for collaboration.</p> <p>Tech Standards: S3</p> <p>Epic: E5330</p> <p>Building Block: Workspace</p> <p>How-To:</p> <ol> <li>Upload Data to Workspace Buckets: Upload data files to the workspace\u2019s S3 buckets.</li> <li>Share Data with Collaborators: Grant access to the workspace buckets to collaborators, allowing them to view, download, or modify data.</li> <li>Reference Data: Use data references (e.g., URLs, S3 paths) to link to data stored in the workspace buckets, enabling collaboration without duplicating data.</li> </ol>"},{"location":"usage/howtos/#uc8-data-discovery-and-exploration","title":"UC8: Data Discovery and Exploration","text":"<p>User Story: As a user, I want to have an exhaustive view on all available data in the project/group space.</p> <p>Epic: E5330</p> <p>Building Block: Workspace</p> <p>How-To:</p> <ol> <li>Use Resource Discovery Service: Utilize the Workspace\u2019s resource discovery service to browse and search for available data within the workspace.</li> <li>Explore Data Metadata: Access metadata associated with data files, including file size, format, and creation date.</li> <li>Filter and Sort Data: Filter and sort data based on specific criteria to find relevant information.</li> </ol>"},{"location":"usage/howtos/#uc9-data-change-tracking","title":"UC9: Data Change Tracking","text":"<p>User Story: As a user, I want to be able to trace changes on data.</p> <p>Epic: E5330</p> <p>Building Block: Workspace</p> <p>How-To:</p> <ol> <li>Enable Versioning: Configure versioning for the workspace\u2019s S3 buckets to track changes to data files.</li> <li>Access Data History: View previous versions of data files and track changes made over time.</li> <li>Restore Previous Versions: Restore previous versions of data files if needed.</li> </ol>"},{"location":"usage/howtos/#uc10-reproducible-data-exploration-and-processing","title":"UC10: Reproducible Data Exploration and Processing","text":"<p>User Story: As a user, I want to be able to explore / process / experiment with stable snapshots of data for reproducibility in a scalable way with common software libraries.</p> <p>Tech Standards: S3, fsspec</p> <p>Epic: E5330</p> <p>Building Block: Workspace</p> <p>How-To:</p> <ol> <li>Create Data Snapshots: Create snapshots of data within the workspace\u2019s S3 buckets to ensure reproducibility.</li> <li>Use fsspec for Data Access: Utilize the fsspec library to access data snapshots from within your analysis environment.</li> <li>Scale Data Processing: Leverage the scalability of the underlying infrastructure to process large datasets efficiently.</li> </ol>"},{"location":"usage/howtos/#application-hub-building-block_1","title":"Application Hub Building Block","text":""},{"location":"usage/howtos/#uc11-familiar-data-libraries-and-tools","title":"UC11: Familiar Data Libraries and Tools","text":"<p>User Story: As a user, I want to use my familiar data library and tool stack for exploration and curation.</p> <p>Tech Standards: Kubernetes, Helm</p> <p>Epic: E5350</p> <p>Building Block: Workspace</p> <p>How-To:</p> <ol> <li>Install Data Libraries: Install your preferred data libraries and tools within your workspace using Helm charts from the Application Hub.</li> <li>Configure Libraries: Configure the installed libraries and tools to access data within the workspace.</li> <li>Use Familiar Tools: Utilize your familiar data libraries and tools for exploration, analysis, and curation.</li> </ol>"},{"location":"usage/howtos/#uc12-custom-applications-and-tools","title":"UC12: Custom Applications and Tools","text":"<p>User Story: As a user, I want to bring a custom set of existing applications and tools close to the data.</p> <p>Tech Standards: Kubernetes, Helm</p> <p>Epic: E5360</p> <p>Building Block: Workspace, Application Hub, MLOps</p> <p>How-To:</p> <ol> <li>Package Applications as Helm Charts: Package your custom applications and tools as Helm charts.</li> <li>Publish Charts to Application Hub: Publish the Helm charts to the Application Hub.</li> <li>Deploy Applications to Workspace: Deploy your custom applications and tools to your workspace using Helm.</li> </ol>"},{"location":"usage/tutorials/","title":"Tutorials","text":"<p>Tutorials as a learning aid.</p>"}]}