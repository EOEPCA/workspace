---
# Source: csi-rclone/templates/csi-controller-rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: csi-rclone-controller
  namespace: workspace
  labels:
    helm.sh/chart: csi-rclone-0.3.5
    app.kubernetes.io/name: csi-rclone
    app.kubernetes.io/instance: csi-rclone
    app.kubernetes.io/version: "0.1.7"
    app.kubernetes.io/managed-by: Helm
  annotations:
    {}
---
# Source: csi-rclone/templates/csi-nodeplugin-rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: csi-rclone-nodeplugin
  namespace: workspace
  labels:
    helm.sh/chart: csi-rclone-0.3.5
    app.kubernetes.io/name: csi-rclone
    app.kubernetes.io/instance: csi-rclone
    app.kubernetes.io/version: "0.1.7"
    app.kubernetes.io/managed-by: Helm
  annotations:
    {}
---
# Source: csi-rclone/templates/csi-rclone-storageclass.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: csi-rclone
  labels:
    helm.sh/chart: csi-rclone-0.3.5
    app.kubernetes.io/name: csi-rclone
    app.kubernetes.io/instance: csi-rclone
    app.kubernetes.io/version: "0.1.7"
    app.kubernetes.io/managed-by: Helm
provisioner: csi-rclone
volumeBindingMode: Immediate
reclaimPolicy: Delete
# ---
# # Source: csi-rclone/templates/csi-rclone-storageclass.yaml
# apiVersion: storage.k8s.io/v1
# kind: StorageClass
# metadata:
#   name: csi-rclone-secret-annotation
#   labels:
#     helm.sh/chart: csi-rclone-0.3.5
#     app.kubernetes.io/name: csi-rclone
#     app.kubernetes.io/instance: csi-rclone
#     app.kubernetes.io/version: "0.1.7"
#     app.kubernetes.io/managed-by: Helm
# provisioner: csi-rclone
# volumeBindingMode: Immediate
# reclaimPolicy: Delete
# parameters:
#   # CreateVolumeRequest.secrets or DeleteVolumeRequest.secrets
#   # If creating a PersistentVolume by hand then these are not needed, see below
#   csi.storage.k8s.io/provisioner-secret-name: ${pvc.annotations['csi-rclone.dev/secretName']}
#   csi.storage.k8s.io/provisioner-secret-namespace: ${pvc.namespace}
#   # Populates NodePublishVolumeRequest.secrets
#   # If creating a PersistentVolume by hand then set spec.csi.nodePublishSecretRef.name and spec.csi.NodePublishSecretRef.namespace
#   csi.storage.k8s.io/node-publish-secret-name: ${pvc.annotations['csi-rclone.dev/secretName']}
#   csi.storage.k8s.io/node-publish-secret-namespace: ${pvc.namespace}
---
# Source: csi-rclone/templates/csi-controller-rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: csi-rclone-external-controller
  labels:
    helm.sh/chart: csi-rclone-0.3.5
    app.kubernetes.io/name: csi-rclone
    app.kubernetes.io/instance: csi-rclone
    app.kubernetes.io/version: "0.1.7"
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups:
  - ""
  resources:
  - persistentvolumes
  verbs:
  - get
  - list
  - watch
  - update
  - patch
- apiGroups:
  - ""
  resources: 
  - "secrets"
  - "secret"
  verbs:
  - "get"
  - "list"
  - "create" # TODO: check if necessary
- apiGroups:
  - ""
  resources:
  - nodes
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - csi.storage.k8s.io
  resources:
  - csinodeinfos
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - storage.k8s.io
  resources:
  - volumeattachments
  verbs:
  - get
  - list
  - watch
  - update
- apiGroups:
  - storage.k8s.io
  resources:
  - volumeattachments
  verbs:
  - get
  - list
  - watch
  - update
- apiGroups:
  - storage.k8s.io
  resources:
  - volumeattachments/status
  verbs:
  - patch
- apiGroups:
  - coordination.k8s.io
  resources:
  - leases
  verbs:
  - get
  - create
  - update
- apiGroups:
  - ""
  resources:
  - events
  verbs:
  - create
---
# Source: csi-rclone/templates/csi-controller-rbac.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: csi-rclone-external-provisioner-runner
  labels:
    helm.sh/chart: csi-rclone-0.3.5
    app.kubernetes.io/name: csi-rclone
    app.kubernetes.io/instance: csi-rclone
    app.kubernetes.io/version: "0.1.7"
    app.kubernetes.io/managed-by: Helm
rules:
  # The following rule should be uncommented for plugins that require secrets
  # for provisioning.
  - apiGroups: 
    - ""
    resources:
    - "secrets"
    verbs: 
    - "get"
    - "list"
  - apiGroups:
    - ""
    resources:
    - "persistentvolumes"
    verbs: 
    - "get"
    - "list"
    - "watch"
    - "create"
    - "delete"
  - apiGroups: 
    - ""
    resources:
    - "persistentvolumeclaims"
    verbs:
    - "get"
    - "list"
    - "watch"
    - "update"
  - apiGroups: 
    - "storage.k8s.io"
    resources:
    - "storageclasses"
    verbs: 
    - "get"
    - "list"
    - "watch"
  - apiGroups:
    - ""
    resources:
    - "events"
    verbs:
    - "list"
    - "watch"
    - "create"
    - "update"
    - "patch"
  - apiGroups: 
    - "snapshot.storage.k8s.io"
    resources: 
    - "volumesnapshots"
    verbs: 
    - "get"
    - "list"
  - apiGroups: 
    - "snapshot.storage.k8s.io"
    resources: 
    - "volumesnapshotcontents"
    verbs: 
    - "get"
    - "list"
  - apiGroups: 
    - "storage.k8s.io"
    resources: 
    - "csinodes"
    verbs: 
    - "get"
    - "list"
    - "watch"
  - apiGroups:
    - ""
    resources: 
    - "nodes"
    verbs: 
    - "get"
    - "list"
    - "watch"
  # Access to volumeattachments is only needed when the CSI driver
  # has the PUBLISH_UNPUBLISH_VOLUME controller capability.
  # In that case, external-provisioner will watch volumeattachments
  # to determine when it is safe to delete a volume.
  - apiGroups: 
    - "storage.k8s.io"
    resources: 
    - "volumeattachments"
    verbs: 
    - "get"
    - "list"
    - "watch"
---
# Source: csi-rclone/templates/csi-nodeplugin-rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: csi-rclone-nodeplugin
  labels:
    helm.sh/chart: csi-rclone-0.3.5
    app.kubernetes.io/name: csi-rclone
    app.kubernetes.io/instance: csi-rclone
    app.kubernetes.io/version: "0.1.7"
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups:
  - ""
  resources:
  - persistentvolumes
  verbs:
  - get
  - list
  - watch
  - update
- apiGroups:
  - ""
  resources:
  - secrets
  - secret
  verbs:
  - get
  - list
  - create
  - delete
- apiGroups:
  - ""
  resources: 
  - pods
  verbs:
  - list
  - watch
- apiGroups:
  - apps
  resources:
  - deployments
  - deploy
  - deployment
  verbs: 
  - get
  - list
  - create
  - delete
  - watch
  - patch
  - update
- apiGroups:
  - ""
  resources:
  - nodes
  verbs:
  - get
  - list
  - watch
  - update
- apiGroups:
  - storage.k8s.io
  resources:
  - volumeattachments
  verbs:
  - get
  - list
  - watch
  - update
- apiGroups:
  - ""
  resources:
  - events
  verbs:
  - get
  - list
  - watch
  - create
  - update
  - patch
---
# Source: csi-rclone/templates/csi-controller-rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: csi-rclone-attacher-role
  labels:
    helm.sh/chart: csi-rclone-0.3.5
    app.kubernetes.io/name: csi-rclone
    app.kubernetes.io/instance: csi-rclone
    app.kubernetes.io/version: "0.1.7"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: 'csi-rclone-external-controller'
subjects:
- kind: ServiceAccount
  name: 'csi-rclone-controller'
  namespace: workspace
---
# Source: csi-rclone/templates/csi-controller-rbac.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: csi-rclone-provisioner-role
  labels:
    helm.sh/chart: csi-rclone-0.3.5
    app.kubernetes.io/name: csi-rclone
    app.kubernetes.io/instance: csi-rclone
    app.kubernetes.io/version: "0.1.7"
    app.kubernetes.io/managed-by: Helm
subjects:
  - kind: ServiceAccount
    name: 'csi-rclone-controller'
    namespace: 'workspace'
roleRef:
  kind: ClusterRole
  name: 'csi-rclone-external-provisioner-runner'
  apiGroup: rbac.authorization.k8s.io
---
# Source: csi-rclone/templates/csi-nodeplugin-rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: csi-rclone-nodeplugin
  labels:
    helm.sh/chart: csi-rclone-0.3.5
    app.kubernetes.io/name: csi-rclone
    app.kubernetes.io/instance: csi-rclone
    app.kubernetes.io/version: "0.1.7"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: 'csi-rclone-nodeplugin'
subjects:
- kind: ServiceAccount
  name: 'csi-rclone-nodeplugin'
  namespace: 'workspace'
---
# Source: csi-rclone/templates/csi-controller-rbac.yaml
# Provisioner must be able to work with endpoints in current namespace
# if (and only if) leadership election is enabled
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: csi-rclone-external-provisioner-cfg
  namespace: workspace
rules:
# Only one of the following rules for endpoints or leases is required based on
# what is set for `--leader-election-type`. Endpoints are deprecated in favor of Leases.
- apiGroups: 
  - ""
  resources: 
  - "endpoints"
  verbs:
  - "get"
  - "watch"
  - "list"
  - "delete"
  - "update"
  - "create"
- apiGroups: 
  - "coordination.k8s.io"
  resources:
  - "leases"
  verbs: 
  - "get"
  - "watch"
  - "list"
  - "delete"
  - "update"
  - "create"
# Permissions for CSIStorageCapacity are only needed enabling the publishing
# of storage capacity information.
- apiGroups: 
  - "storage.k8s.io"
  resources: 
  - "csistoragecapacities"
  verbs: 
  - "get"
  - "list"
  - "watch"
  - "create"
  - "update"
  - "patch"
  - "delete"
# The GET permissions below are needed for walking up the ownership chain
# for CSIStorageCapacity. They are sufficient for deployment via
# StatefulSet (only needs to get Pod) and Deployment (needs to get
# Pod and then ReplicaSet to find the Deployment).
- apiGroups: 
  - ""
  resources: 
  - "pods"
  verbs: 
  - "get"
---
# Source: csi-rclone/templates/csi-controller-rbac.yaml
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: csi-rclone-provisioner-role-cfg
  namespace: 'workspace'
subjects:
  - kind: ServiceAccount
    name: csi-rclone-controller
    namespace: workspace
roleRef:
  kind: Role
  name: csi-rclone-external-provisioner-cfg
  apiGroup: rbac.authorization.k8s.io
---
# Source: csi-rclone/templates/csi-nodeplugin-rclone.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: csi-rclone-nodeplugin
  namespace: workspace
  labels:
    helm.sh/chart: csi-rclone-0.3.5
    app.kubernetes.io/name: csi-rclone
    app.kubernetes.io/instance: csi-rclone
    app.kubernetes.io/version: "0.1.7"
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      app: csi-nodeplugin-rclone
      app.kubernetes.io/name: csi-rclone
      app.kubernetes.io/instance: csi-rclone
  template:
    metadata:
      labels:
        app: csi-nodeplugin-rclone
        app.kubernetes.io/name: csi-rclone
        app.kubernetes.io/instance: csi-rclone
    spec:
      serviceAccountName: csi-rclone-nodeplugin
      dnsPolicy: ClusterFirstWithHostNet
      containers:
      - name: node-driver-registrar
        args:
        - --v=5
        - --csi-address=/plugin/csi.sock
        - --kubelet-registration-path=/var/lib/kubelet/plugins/csi-rclone/csi.sock
        env:
        - name: KUBE_NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        - name: KUBERNETES_CLUSTER_DOMAIN
          value: "cluster.local"
        image: registry.k8s.io/sig-storage/csi-node-driver-registrar:v2.12.0
        imagePullPolicy: IfNotPresent
        lifecycle:
          preStop:
            exec:
              command:
              - /bin/sh
              - -c
              - rm -rf /registration/csi-rclone /registration/csi-rclone-reg.sock
        resources:
            {}
        volumeMounts:
        - mountPath: /plugin
          name: plugin-dir
        - mountPath: /registration
          name: registration-dir
      - name: liveness-probe
        imagePullPolicy: Always
        image: registry.k8s.io/sig-storage/livenessprobe:v2.11.0
        args:
        - --csi-address=/plugin/csi.sock
        volumeMounts:
        - mountPath: /plugin
          name: plugin-dir
      - name: rclone
        args:
        - run
        - --nodeid=$(NODE_ID)
        - --endpoint=$(CSI_ENDPOINT)
        env:
        - name: NODE_ID
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        - name: CSI_ENDPOINT
          value: "unix://plugin/csi.sock"
        - name: KUBERNETES_CLUSTER_DOMAIN
          value: "cluster.local"
        - name: DRIVER_NAME
          value: "csi-rclone"
        - name: LOG_LEVEL
          value: "NOTICE"
        image: renku/csi-rclone:v0.3.5
        imagePullPolicy: IfNotPresent
        # TODO: check if necessary
        lifecycle:
          postStart:
            exec:
              command:
              - /bin/sh
              - -c
              - mount -t fuse.rclone | while read -r mount; do umount $(echo $mount | awk {print $3}) ; done
        resources:
            {}
        securityContext:
          allowPrivilegeEscalation: true
          capabilities:
            add:
            - SYS_ADMIN
          privileged: true
        ports:
          - containerPort: 9808
            name: healthz
            protocol: TCP
        livenessProbe:
          failureThreshold: 5
          httpGet:
            path: /healthz
            port: healthz
          initialDelaySeconds: 30
          timeoutSeconds: 10
          periodSeconds: 30
        volumeMounts:
        - mountPath: /plugin
          name: plugin-dir
        - mountPath: /var/lib/kubelet/pods
          mountPropagation: Bidirectional
          name: pods-mount-dir
      volumes:
      - hostPath:
          path: /var/lib/kubelet/plugins/csi-rclone
          type: DirectoryOrCreate
        name: plugin-dir
      - hostPath:
          path: /var/lib/kubelet/pods
          type: Directory
        name: pods-mount-dir
      - hostPath:
          path: /var/lib/kubelet/plugins_registry
          type: DirectoryOrCreate
        name: registration-dir
---
# Source: csi-rclone/templates/csi-controller-rclone.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: csi-rclone-controller
  namespace: workspace
  labels:
    helm.sh/chart: csi-rclone-0.3.5
    app.kubernetes.io/name: csi-rclone
    app.kubernetes.io/instance: csi-rclone
    app.kubernetes.io/version: "0.1.7"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app: csi-controller-rclone
  serviceName: csi-rclone-controller
  template:
    metadata:
      labels:
        app: csi-controller-rclone
    spec:
      serviceAccountName: csi-rclone-controller
      containers:
      - name: csi-attacher
        args:
        - --v=5
        - --csi-address=$(ADDRESS)
        - --leader-election

        env:
        - name: ADDRESS
          value: "/csi/csi.sock"
        - name: KUBERNETES_CLUSTER_DOMAIN
          value: "cluster.local"
        image: registry.k8s.io/sig-storage/csi-attacher:v4.7.0
        imagePullPolicy: IfNotPresent
        resources: {}
        volumeMounts:
        - mountPath: /csi
          name: socket-dir
      - name: csi-provisioner
        args:
        - --csi-address=$(ADDRESS)
        - --capacity-ownerref-level=0
        - "--extra-create-metadata" # do not remove this, it is required for correct functioning
        env:
        - name: ADDRESS
          value: "/csi/csi.sock"
        - name: NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        image: registry.k8s.io/sig-storage/csi-provisioner:v5.1.0
        imagePullPolicy: IfNotPresent
        volumeMounts:
          - name: socket-dir
            mountPath: /csi
      - name: rclone
        args:
        - run
        - --nodeid=$(NODE_ID)
        - --endpoint=$(CSI_ENDPOINT)
        env:
        - name: DRIVER_NAME
          value: "csi-rclone"
        - name: NODE_ID
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        - name: CSI_ENDPOINT
          value: "unix://plugin/csi.sock"
        - name: KUBERNETES_CLUSTER_DOMAIN
          value: "cluster.local"
        image: renku/csi-rclone:v0.3.5
        imagePullPolicy: IfNotPresent
        resources:
            {}
        ports:
        - containerPort: 9808
          name: healthz
          protocol: TCP
        livenessProbe:
          failureThreshold: 5
          httpGet:
            path: /healthz
            port: healthz
          initialDelaySeconds: 10
          timeoutSeconds: 3
          periodSeconds: 2
        volumeMounts:
        - mountPath: /plugin
          name: socket-dir
      - name: liveness-probe
        imagePullPolicy: Always
        image: registry.k8s.io/sig-storage/livenessprobe:v2.11.0
        args:
        - --csi-address=/csi/csi.sock
        volumeMounts:
        - mountPath: /csi
          name: socket-dir
      volumes:
      - emptyDir: {}
        name: socket-dir
  updateStrategy: {}
---
# Source: csi-rclone/templates/csi-driver.yaml
apiVersion: storage.k8s.io/v1
kind: CSIDriver
metadata:
  name: csi-rclone-driver
  labels:
    helm.sh/chart: csi-rclone-0.3.5
    app.kubernetes.io/name: csi-rclone
    app.kubernetes.io/instance: csi-rclone
    app.kubernetes.io/version: "0.1.7"
    app.kubernetes.io/managed-by: Helm
spec:
  attachRequired: true
  podInfoOnMount: false  # are we sure about this?
  volumeLifecycleModes:
    - Persistent
    - Ephemeral

